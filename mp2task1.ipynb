{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bdaf485-5856-42a8-9f4b-b5a75d68bd50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.efficientnet = models.efficientnet_b0(pretrained=True)\n",
    "        self.efficientnet.eval()\n",
    "        self.efficientnet.classifier = nn.Identity()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, 224, 224)\n",
    "            feature_dim = self.efficientnet(dummy_input).shape[1]\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = Resize((160, 160))(x)\n",
    "        x = self.efficientnet(x)\n",
    "        return x\n",
    "\n",
    "def compute_prototypes(features, labels, n_classes):\n",
    "    \"\"\"Compute prototypes for each class\"\"\"\n",
    "    prototypes = []\n",
    "    for class_idx in range(n_classes):\n",
    "        class_features = features[labels == class_idx]\n",
    "        if len(class_features) > 0:\n",
    "            class_prototype = class_features.mean(0)\n",
    "            prototypes.append(class_prototype)\n",
    "    return torch.stack(prototypes)\n",
    "\n",
    "class ContinualLearner:\n",
    "    def __init__(self, feature_extractor, n_classes=10):\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.n_classes = n_classes\n",
    "        self.prototypes = None\n",
    "        \n",
    "    def extract_features(self, dataloader):\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                if isinstance(batch, (tuple, list)):\n",
    "                    images, labels = batch\n",
    "                    all_labels.append(labels)\n",
    "                else:\n",
    "                    images = batch\n",
    "                features = self.feature_extractor(images)\n",
    "                all_features.append(features)\n",
    "        \n",
    "        features = torch.cat(all_features)\n",
    "        labels = torch.cat(all_labels) if all_labels else None\n",
    "        return features, labels\n",
    "\n",
    "    def assign_pseudo_labels(self, features):\n",
    "        \"\"\"Assign pseudo-labels using current prototypes\"\"\"\n",
    "        distances = torch.cdist(features, self.prototypes)\n",
    "        pseudo_labels = torch.argmin(distances, dim=1)\n",
    "        confidence_scores = torch.softmax(-distances, dim=1).max(dim=1)[0]\n",
    "        return pseudo_labels, confidence_scores\n",
    "\n",
    "    def update_prototypes(self, features, pseudo_labels, confidence_scores, threshold=0):\n",
    "        \"\"\"Update prototypes using high-confidence samples\"\"\"\n",
    "        new_prototypes = []\n",
    "        for class_idx in range(self.n_classes):\n",
    "            mask = (pseudo_labels == class_idx) & (confidence_scores > threshold)\n",
    "            if mask.sum() > 0:\n",
    "                class_features = features[mask]\n",
    "                new_prototype = class_features.mean(0)\n",
    "                new_prototypes.append(new_prototype)\n",
    "            else:\n",
    "                new_prototypes.append(self.prototypes[class_idx])\n",
    "        return torch.stack(new_prototypes)\n",
    "\n",
    "    def train_iteration(self, train_loader, initial=False):\n",
    "        \"\"\"Train on a new dataset\"\"\"\n",
    "        features, labels = self.extract_features(train_loader)\n",
    "        \n",
    "        if initial:\n",
    "            # For the first dataset, use true labels\n",
    "            self.prototypes = compute_prototypes(features, labels, self.n_classes)\n",
    "        else:\n",
    "            # For subsequent datasets, use pseudo-labels\n",
    "            pseudo_labels, confidence_scores = self.assign_pseudo_labels(features)\n",
    "            self.prototypes = 0.8 * self.prototypes + 0.2 * self.update_prototypes(\n",
    "                features, pseudo_labels, confidence_scores\n",
    "            )\n",
    "\n",
    "    def evaluate(self, eval_loader):\n",
    "        \"\"\"Evaluate on a labeled dataset\"\"\"\n",
    "        features, labels = self.extract_features(eval_loader)\n",
    "        distances = torch.cdist(features, self.prototypes)\n",
    "        predictions = torch.argmin(distances, dim=1)\n",
    "        return accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "\n",
    "def load_dataset(path, has_labels=False):\n",
    "    \"\"\"Load and preprocess dataset\"\"\"\n",
    "    data = torch.load(path)\n",
    "    images = torch.tensor(data['data'], dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "    \n",
    "    # Normalize using ImageNet statistics\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])\n",
    "    images = (images / 255.0 - mean.view(1, 3, 1, 1)) / std.view(1, 3, 1, 1)\n",
    "    \n",
    "    if has_labels:\n",
    "        labels = torch.tensor(data['targets'], dtype=torch.long)\n",
    "        return DataLoader(list(zip(images, labels)), batch_size=64, shuffle=True)\n",
    "    return DataLoader(images, batch_size=64, shuffle=False)\n",
    "\n",
    "def train_on_d1(base_path, eval_base_path):\n",
    "    \"\"\"\n",
    "    Function to train the model on dataset D1 and evaluate on D1.\n",
    "    This should be run first.\n",
    "    \"\"\"\n",
    "    # Initialize feature extractor and learner\n",
    "    feature_extractor = FeatureExtractor()\n",
    "    learner = ContinualLearner(feature_extractor)\n",
    "    \n",
    "    # Load D1 training and evaluation data\n",
    "    print(\"Training on D1...\")\n",
    "    d1_train = load_dataset(f\"{base_path}/1_train_data.tar.pth\", has_labels=True)\n",
    "    d1_eval = load_dataset(f\"{eval_base_path}/1_eval_data.tar.pth\", has_labels=True)\n",
    "    \n",
    "    # Train on D1\n",
    "    learner.train_iteration(d1_train, initial=True)\n",
    "    \n",
    "    # Evaluate on D1\n",
    "    accuracy = learner.evaluate(d1_eval)\n",
    "    print(f\"Initial accuracy on D1: {accuracy:.4f}\")\n",
    "    \n",
    "    return learner, accuracy\n",
    "\n",
    "\n",
    "def train_subsequent_datasets(base_path, eval_base_path, learner, num_datasets=10):\n",
    "    \"\"\"\n",
    "    Function to train the model on subsequent datasets and evaluate on previous datasets.\n",
    "    This function should be run after training on D1.\n",
    "    \"\"\"\n",
    "    # Initialize results matrix\n",
    "    accuracies = np.zeros((num_datasets, num_datasets))\n",
    "    \n",
    "    # Record D1 accuracy\n",
    "    accuracies[0, 0] = learner.evaluate(load_dataset(f\"{eval_base_path}/1_eval_data.tar.pth\", has_labels=True))\n",
    "    \n",
    "    # Train on subsequent datasets (D2 to Dn)\n",
    "    for i in range(2, num_datasets + 1):\n",
    "        print(f\"\\nProcessing dataset D{i}\")\n",
    "        \n",
    "        # Load current training dataset\n",
    "        train_data = load_dataset(f\"{base_path}/{i}_train_data.tar.pth\", has_labels=False)\n",
    "        \n",
    "        # Train on current dataset\n",
    "        learner.train_iteration(train_data, initial=False)\n",
    "        \n",
    "        # Evaluate on D1\n",
    "        for j in range(1, i+1):\n",
    "            eval_data = load_dataset(f\"{eval_base_path}/{j}_eval_data.tar.pth\", has_labels=True)\n",
    "            accuracy = learner.evaluate(eval_data)\n",
    "            accuracies[i-1, j-1] = accuracy\n",
    "            print(f\"Model {i} accuracy on D{j}: {accuracy:.4f}\")\n",
    "    \n",
    "    return accuracies\n",
    "\n",
    "# Example of usage in Jupyter cells:\n",
    "\n",
    "# Cell 1: Train on D1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f7a2aa-941b-40fc-86ae-f945a3443ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on D1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prans\\anaconda3\\envs\\mlmini2\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prans\\anaconda3\\envs\\mlmini2\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on D1...\n",
      "Initial accuracy on D1: 0.8468\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_path = \"dataset/part_one_dataset/train_data\"\n",
    "    eval_base_path = \"dataset/part_one_dataset/eval_data\"\n",
    "    \n",
    "    print(\"Starting training on D1...\")\n",
    "    learner, initial_accuracy = train_on_d1(base_path, eval_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5a6157-02bf-45e1-8409-09acbd2c6cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting continual learning training on subsequent datasets...\n",
      "\n",
      "Processing dataset D2\n",
      "Model 2 accuracy on D1: 0.8428\n",
      "Model 2 accuracy on D2: 0.8472\n",
      "\n",
      "Processing dataset D3\n",
      "Model 3 accuracy on D1: 0.8444\n",
      "Model 3 accuracy on D2: 0.8452\n",
      "Model 3 accuracy on D3: 0.8344\n",
      "\n",
      "Processing dataset D4\n",
      "Model 4 accuracy on D1: 0.8396\n",
      "Model 4 accuracy on D2: 0.8440\n",
      "Model 4 accuracy on D3: 0.8340\n",
      "Model 4 accuracy on D4: 0.8384\n",
      "\n",
      "Processing dataset D5\n",
      "Model 5 accuracy on D1: 0.8356\n",
      "Model 5 accuracy on D2: 0.8400\n",
      "Model 5 accuracy on D3: 0.8344\n",
      "Model 5 accuracy on D4: 0.8388\n",
      "Model 5 accuracy on D5: 0.8416\n",
      "\n",
      "Processing dataset D6\n",
      "Model 6 accuracy on D1: 0.8336\n",
      "Model 6 accuracy on D2: 0.8356\n",
      "Model 6 accuracy on D3: 0.8268\n",
      "Model 6 accuracy on D4: 0.8336\n",
      "Model 6 accuracy on D5: 0.8388\n",
      "Model 6 accuracy on D6: 0.8308\n",
      "\n",
      "Processing dataset D7\n",
      "Model 7 accuracy on D1: 0.8324\n",
      "Model 7 accuracy on D2: 0.8352\n",
      "Model 7 accuracy on D3: 0.8228\n",
      "Model 7 accuracy on D4: 0.8320\n",
      "Model 7 accuracy on D5: 0.8376\n",
      "Model 7 accuracy on D6: 0.8308\n",
      "Model 7 accuracy on D7: 0.8192\n",
      "\n",
      "Processing dataset D8\n",
      "Model 8 accuracy on D1: 0.8300\n",
      "Model 8 accuracy on D2: 0.8328\n",
      "Model 8 accuracy on D3: 0.8188\n",
      "Model 8 accuracy on D4: 0.8308\n",
      "Model 8 accuracy on D5: 0.8356\n",
      "Model 8 accuracy on D6: 0.8272\n",
      "Model 8 accuracy on D7: 0.8140\n",
      "Model 8 accuracy on D8: 0.8268\n",
      "\n",
      "Processing dataset D9\n",
      "Model 9 accuracy on D1: 0.8272\n",
      "Model 9 accuracy on D2: 0.8316\n",
      "Model 9 accuracy on D3: 0.8200\n",
      "Model 9 accuracy on D4: 0.8292\n",
      "Model 9 accuracy on D5: 0.8356\n",
      "Model 9 accuracy on D6: 0.8268\n",
      "Model 9 accuracy on D7: 0.8144\n",
      "Model 9 accuracy on D8: 0.8252\n",
      "Model 9 accuracy on D9: 0.8132\n",
      "\n",
      "Processing dataset D10\n",
      "Model 10 accuracy on D1: 0.8276\n",
      "Model 10 accuracy on D2: 0.8312\n",
      "Model 10 accuracy on D3: 0.8204\n",
      "Model 10 accuracy on D4: 0.8248\n",
      "Model 10 accuracy on D5: 0.8360\n",
      "Model 10 accuracy on D6: 0.8228\n",
      "Model 10 accuracy on D7: 0.8156\n",
      "Model 10 accuracy on D8: 0.8236\n",
      "Model 10 accuracy on D9: 0.8100\n",
      "Model 10 accuracy on D10: 0.8452\n",
      "\n",
      "Final Accuracy Matrix:\n",
      "[[0.8468 0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.8428 0.8472 0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.8444 0.8452 0.8344 0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.8396 0.844  0.834  0.8384 0.     0.     0.     0.     0.     0.    ]\n",
      " [0.8356 0.84   0.8344 0.8388 0.8416 0.     0.     0.     0.     0.    ]\n",
      " [0.8336 0.8356 0.8268 0.8336 0.8388 0.8308 0.     0.     0.     0.    ]\n",
      " [0.8324 0.8352 0.8228 0.832  0.8376 0.8308 0.8192 0.     0.     0.    ]\n",
      " [0.83   0.8328 0.8188 0.8308 0.8356 0.8272 0.814  0.8268 0.     0.    ]\n",
      " [0.8272 0.8316 0.82   0.8292 0.8356 0.8268 0.8144 0.8252 0.8132 0.    ]\n",
      " [0.8276 0.8312 0.8204 0.8248 0.836  0.8228 0.8156 0.8236 0.81   0.8452]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_datasets = 10\n",
    "    print(\"Starting continual learning training on subsequent datasets...\")\n",
    "    accuracies = train_subsequent_datasets(base_path, eval_base_path, learner, num_datasets)\n",
    "    \n",
    "    print(\"\\nFinal Accuracy Matrix:\")\n",
    "    print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b098ea-21cd-4feb-8f41-36ba00cd75d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
