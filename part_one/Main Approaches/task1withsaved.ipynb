{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7e5bd-14a7-4c17-b86b-afd21798d8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on D1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prans\\anaconda3\\envs\\mlmini2\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prans\\anaconda3\\envs\\mlmini2\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on D1...\n",
      "Loading saved training features for dataset 1 from saved_data\\features_dataset_1.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data\\eval_features_dataset_1.pth\n",
      "Initial accuracy on D1: 0.8468\n",
      "Starting continual learning training on subsequent datasets...\n",
      "Dataset ID not provided, extracting features directly...\n",
      "\n",
      "Processing dataset D2\n",
      "Loading saved training features for dataset 2 from saved_data\\features_dataset_2.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data\\eval_features_dataset_1.pth\n",
      "Model 2 accuracy on D1: 0.8428\n",
      "Loading saved features for evaluation dataset 2 from saved_data\\eval_features_dataset_2.pth\n",
      "Model 2 accuracy on D2: 0.8472\n",
      "\n",
      "Processing dataset D3\n",
      "Loading saved training features for dataset 3 from saved_data\\features_dataset_3.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data\\eval_features_dataset_1.pth\n",
      "Model 3 accuracy on D1: 0.8444\n",
      "Loading saved features for evaluation dataset 2 from saved_data\\eval_features_dataset_2.pth\n",
      "Model 3 accuracy on D2: 0.8452\n",
      "Loading saved features for evaluation dataset 3 from saved_data\\eval_features_dataset_3.pth\n",
      "Model 3 accuracy on D3: 0.8344\n",
      "\n",
      "Processing dataset D4\n",
      "Loading saved training features for dataset 4 from saved_data\\features_dataset_4.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data\\eval_features_dataset_1.pth\n",
      "Model 4 accuracy on D1: 0.8396\n",
      "Loading saved features for evaluation dataset 2 from saved_data\\eval_features_dataset_2.pth\n",
      "Model 4 accuracy on D2: 0.8440\n",
      "Loading saved features for evaluation dataset 3 from saved_data\\eval_features_dataset_3.pth\n",
      "Model 4 accuracy on D3: 0.8340\n",
      "Loading saved features for evaluation dataset 4 from saved_data\\eval_features_dataset_4.pth\n",
      "Model 4 accuracy on D4: 0.8384\n",
      "\n",
      "Processing dataset D5\n",
      "Loading saved training features for dataset 5 from saved_data\\features_dataset_5.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data\\eval_features_dataset_1.pth\n",
      "Model 5 accuracy on D1: 0.8356\n",
      "Loading saved features for evaluation dataset 2 from saved_data\\eval_features_dataset_2.pth\n",
      "Model 5 accuracy on D2: 0.8400\n",
      "Loading saved features for evaluation dataset 3 from saved_data\\eval_features_dataset_3.pth\n",
      "Model 5 accuracy on D3: 0.8344\n",
      "Loading saved features for evaluation dataset 4 from saved_data\\eval_features_dataset_4.pth\n",
      "Model 5 accuracy on D4: 0.8388\n",
      "Loading saved features for evaluation dataset 5 from saved_data\\eval_features_dataset_5.pth\n",
      "Model 5 accuracy on D5: 0.8416\n",
      "\n",
      "Processing dataset D6\n",
      "Loading saved training features for dataset 6 from saved_data\\features_dataset_6.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data\\eval_features_dataset_1.pth\n",
      "Model 6 accuracy on D1: 0.8336\n",
      "Loading saved features for evaluation dataset 2 from saved_data\\eval_features_dataset_2.pth\n",
      "Model 6 accuracy on D2: 0.8356\n",
      "Loading saved features for evaluation dataset 3 from saved_data\\eval_features_dataset_3.pth\n",
      "Model 6 accuracy on D3: 0.8268\n",
      "Loading saved features for evaluation dataset 4 from saved_data\\eval_features_dataset_4.pth\n",
      "Model 6 accuracy on D4: 0.8336\n",
      "Loading saved features for evaluation dataset 5 from saved_data\\eval_features_dataset_5.pth\n",
      "Model 6 accuracy on D5: 0.8388\n",
      "Loading saved features for evaluation dataset 6 from saved_data\\eval_features_dataset_6.pth\n",
      "Model 6 accuracy on D6: 0.8308\n",
      "\n",
      "Processing dataset D7\n",
      "Loading saved training features for dataset 7 from saved_data\\features_dataset_7.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data\\eval_features_dataset_1.pth\n",
      "Model 7 accuracy on D1: 0.8324\n",
      "Loading saved features for evaluation dataset 2 from saved_data\\eval_features_dataset_2.pth\n",
      "Model 7 accuracy on D2: 0.8352\n",
      "Loading saved features for evaluation dataset 3 from saved_data\\eval_features_dataset_3.pth\n",
      "Model 7 accuracy on D3: 0.8228\n",
      "Loading saved features for evaluation dataset 4 from saved_data\\eval_features_dataset_4.pth\n",
      "Model 7 accuracy on D4: 0.8320\n",
      "Loading saved features for evaluation dataset 5 from saved_data\\eval_features_dataset_5.pth\n",
      "Model 7 accuracy on D5: 0.8376\n",
      "Loading saved features for evaluation dataset 6 from saved_data\\eval_features_dataset_6.pth\n",
      "Model 7 accuracy on D6: 0.8308\n",
      "Loading saved features for evaluation dataset 7 from saved_data\\eval_features_dataset_7.pth\n",
      "Model 7 accuracy on D7: 0.8192\n",
      "\n",
      "Processing dataset D8\n",
      "Loading saved training features for dataset 8 from saved_data\\features_dataset_8.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data\\eval_features_dataset_1.pth\n",
      "Model 8 accuracy on D1: 0.8300\n",
      "Loading saved features for evaluation dataset 2 from saved_data\\eval_features_dataset_2.pth\n",
      "Model 8 accuracy on D2: 0.8328\n",
      "Loading saved features for evaluation dataset 3 from saved_data\\eval_features_dataset_3.pth\n",
      "Model 8 accuracy on D3: 0.8188\n",
      "Loading saved features for evaluation dataset 4 from saved_data\\eval_features_dataset_4.pth\n",
      "Model 8 accuracy on D4: 0.8308\n",
      "Loading saved features for evaluation dataset 5 from saved_data\\eval_features_dataset_5.pth\n",
      "Model 8 accuracy on D5: 0.8356\n",
      "Loading saved features for evaluation dataset 6 from saved_data\\eval_features_dataset_6.pth\n",
      "Model 8 accuracy on D6: 0.8272\n",
      "Loading saved features for evaluation dataset 7 from saved_data\\eval_features_dataset_7.pth\n",
      "Model 8 accuracy on D7: 0.8140\n",
      "Loading saved features for evaluation dataset 8 from saved_data\\eval_features_dataset_8.pth\n",
      "Model 8 accuracy on D8: 0.8268\n",
      "\n",
      "Processing dataset D9\n",
      "Loading saved training features for dataset 9 from saved_data\\features_dataset_9.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data\\eval_features_dataset_1.pth\n",
      "Model 9 accuracy on D1: 0.8272\n",
      "Loading saved features for evaluation dataset 2 from saved_data\\eval_features_dataset_2.pth\n",
      "Model 9 accuracy on D2: 0.8316\n",
      "Loading saved features for evaluation dataset 3 from saved_data\\eval_features_dataset_3.pth\n",
      "Model 9 accuracy on D3: 0.8200\n",
      "Loading saved features for evaluation dataset 4 from saved_data\\eval_features_dataset_4.pth\n",
      "Model 9 accuracy on D4: 0.8292\n",
      "Loading saved features for evaluation dataset 5 from saved_data\\eval_features_dataset_5.pth\n",
      "Model 9 accuracy on D5: 0.8356\n",
      "Loading saved features for evaluation dataset 6 from saved_data\\eval_features_dataset_6.pth\n",
      "Model 9 accuracy on D6: 0.8268\n",
      "Loading saved features for evaluation dataset 7 from saved_data\\eval_features_dataset_7.pth\n",
      "Model 9 accuracy on D7: 0.8144\n",
      "Loading saved features for evaluation dataset 8 from saved_data\\eval_features_dataset_8.pth\n",
      "Model 9 accuracy on D8: 0.8252\n",
      "Loading saved features for evaluation dataset 9 from saved_data\\eval_features_dataset_9.pth\n",
      "Model 9 accuracy on D9: 0.8132\n",
      "\n",
      "Processing dataset D10\n",
      "Loading saved training features for dataset 10 from saved_data\\features_dataset_10.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data\\eval_features_dataset_1.pth\n",
      "Model 10 accuracy on D1: 0.8276\n",
      "Loading saved features for evaluation dataset 2 from saved_data\\eval_features_dataset_2.pth\n",
      "Model 10 accuracy on D2: 0.8312\n",
      "Loading saved features for evaluation dataset 3 from saved_data\\eval_features_dataset_3.pth\n",
      "Model 10 accuracy on D3: 0.8204\n",
      "Loading saved features for evaluation dataset 4 from saved_data\\eval_features_dataset_4.pth\n",
      "Model 10 accuracy on D4: 0.8248\n",
      "Loading saved features for evaluation dataset 5 from saved_data\\eval_features_dataset_5.pth\n",
      "Model 10 accuracy on D5: 0.8360\n",
      "Loading saved features for evaluation dataset 6 from saved_data\\eval_features_dataset_6.pth\n",
      "Model 10 accuracy on D6: 0.8228\n",
      "Loading saved features for evaluation dataset 7 from saved_data\\eval_features_dataset_7.pth\n",
      "Model 10 accuracy on D7: 0.8156\n",
      "Loading saved features for evaluation dataset 8 from saved_data\\eval_features_dataset_8.pth\n",
      "Model 10 accuracy on D8: 0.8236\n",
      "Loading saved features for evaluation dataset 9 from saved_data\\eval_features_dataset_9.pth\n",
      "Model 10 accuracy on D9: 0.8100\n",
      "Loading saved features for evaluation dataset 10 from saved_data\\eval_features_dataset_10.pth\n",
      "Model 10 accuracy on D10: 0.8452\n",
      "\n",
      "Final Accuracy Matrix:\n",
      "[[0.8468 0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.8428 0.8472 0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.8444 0.8452 0.8344 0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.8396 0.844  0.834  0.8384 0.     0.     0.     0.     0.     0.    ]\n",
      " [0.8356 0.84   0.8344 0.8388 0.8416 0.     0.     0.     0.     0.    ]\n",
      " [0.8336 0.8356 0.8268 0.8336 0.8388 0.8308 0.     0.     0.     0.    ]\n",
      " [0.8324 0.8352 0.8228 0.832  0.8376 0.8308 0.8192 0.     0.     0.    ]\n",
      " [0.83   0.8328 0.8188 0.8308 0.8356 0.8272 0.814  0.8268 0.     0.    ]\n",
      " [0.8272 0.8316 0.82   0.8292 0.8356 0.8268 0.8144 0.8252 0.8132 0.    ]\n",
      " [0.8276 0.8312 0.8204 0.8248 0.836  0.8228 0.8156 0.8236 0.81   0.8452]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.efficientnet = models.efficientnet_b0(pretrained=True)\n",
    "        self.efficientnet.eval()\n",
    "        self.efficientnet.classifier = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = Resize((160, 160))(x)\n",
    "        x = self.efficientnet(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def compute_prototypes(features, labels, n_classes):\n",
    "    prototypes = []\n",
    "    for class_idx in range(n_classes):\n",
    "        class_features = features[labels == class_idx]\n",
    "        if len(class_features) > 0:\n",
    "            class_prototype = class_features.mean(0)\n",
    "            prototypes.append(class_prototype)\n",
    "    return torch.stack(prototypes)\n",
    "\n",
    "\n",
    "class ContinualLearner:\n",
    "    def __init__(self, feature_extractor, n_classes=10, output_dir=\"saved_data\"):\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.n_classes = n_classes\n",
    "        self.prototypes = None\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def extract_features(self, dataloader):\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                if isinstance(batch, (tuple, list)):\n",
    "                    images, labels = batch\n",
    "                    all_labels.append(labels)\n",
    "                else:\n",
    "                    images = batch\n",
    "                features = self.feature_extractor(images)\n",
    "                all_features.append(features)\n",
    "\n",
    "        features = torch.cat(all_features)\n",
    "        labels = torch.cat(all_labels) if all_labels else None\n",
    "        return features, labels\n",
    "\n",
    "    def save_features(self, features, labels, dataset_id):\n",
    "        torch.save(\n",
    "            {\"features\": features.cpu(), \"labels\": labels.cpu() if labels is not None else None},\n",
    "            os.path.join(self.output_dir, f\"features_dataset_{dataset_id}.pth\"),\n",
    "        )\n",
    "\n",
    "    def save_prototypes(self):\n",
    "        \"\"\"Save the current prototypes to a file.\"\"\"\n",
    "        torch.save(self.prototypes.cpu(), os.path.join(self.output_dir, \"final_prototypes.pth\"))\n",
    "\n",
    "    def assign_pseudo_labels(self, features):\n",
    "        \"\"\"Assign pseudo-labels using current prototypes\"\"\"\n",
    "        distances = torch.cdist(features, self.prototypes)\n",
    "        pseudo_labels = torch.argmin(distances, dim=1)\n",
    "        confidence_scores = torch.softmax(-distances, dim=1).max(dim=1)[0]\n",
    "        return pseudo_labels, confidence_scores\n",
    "\n",
    "    def update_prototypes(self, features, pseudo_labels, confidence_scores, threshold=0):\n",
    "        \"\"\"Update prototypes using high-confidence samples\"\"\"\n",
    "        new_prototypes = []\n",
    "        for class_idx in range(self.n_classes):\n",
    "            mask = (pseudo_labels == class_idx) & (confidence_scores > threshold)\n",
    "            if mask.sum() > 0:\n",
    "                class_features = features[mask]\n",
    "                new_prototype = class_features.mean(0)\n",
    "                new_prototypes.append(new_prototype)\n",
    "            else:\n",
    "                new_prototypes.append(self.prototypes[class_idx])\n",
    "        return torch.stack(new_prototypes)\n",
    "\n",
    "    def train_iteration(self, train_loader, dataset_id=None, initial=False):\n",
    "        \"\"\"Train on a new dataset, using saved features if available.\"\"\"\n",
    "        if dataset_id is not None:\n",
    "            saved_path = os.path.join(self.output_dir, f\"features_dataset_{dataset_id}.pth\")\n",
    "            if os.path.exists(saved_path):\n",
    "                saved_data = torch.load(saved_path)\n",
    "                features = saved_data[\"features\"]\n",
    "                labels = saved_data[\"labels\"]\n",
    "            else:\n",
    "                features, labels = self.extract_features(train_loader)\n",
    "                self.save_features(features, labels, dataset_id)  # Save extracted features for future use\n",
    "        else:\n",
    "            features, labels = self.extract_features(train_loader)\n",
    "\n",
    "        if initial:\n",
    "            # For the first dataset, use true labels\n",
    "            self.prototypes = compute_prototypes(features, labels, self.n_classes)\n",
    "        else:\n",
    "            # For subsequent datasets, use pseudo-labels\n",
    "            pseudo_labels, confidence_scores = self.assign_pseudo_labels(features)\n",
    "            self.prototypes = 0.8 * self.prototypes + 0.2 * self.update_prototypes(\n",
    "                features, pseudo_labels, confidence_scores\n",
    "            )\n",
    "\n",
    "        return features, labels\n",
    "\n",
    "    def save_eval_features(self, features, labels, dataset_id):\n",
    "        torch.save(\n",
    "        {\"features\": features.cpu(), \"labels\": labels.cpu()},\n",
    "        os.path.join(self.output_dir, f\"eval_features_dataset_{dataset_id}.pth\"),\n",
    "        )\n",
    "\n",
    "    def evaluate(self, eval_loader, dataset_id=None):\n",
    "        if dataset_id is not None:\n",
    "            # Check if saved features exist\n",
    "            saved_path = os.path.join(self.output_dir, f\"eval_features_dataset_{dataset_id}.pth\")\n",
    "            if os.path.exists(saved_path):\n",
    "                saved_data = torch.load(saved_path)\n",
    "                features = saved_data[\"features\"]\n",
    "                labels = saved_data[\"labels\"]\n",
    "            else:\n",
    "                features, labels = self.extract_features(eval_loader)\n",
    "                self.save_eval_features(features, labels, dataset_id)  # Save extracted features for future use\n",
    "        else:\n",
    "            features, labels = self.extract_features(eval_loader)\n",
    "\n",
    "        # Perform evaluation using extracted or loaded features\n",
    "        distances = torch.cdist(features, self.prototypes)\n",
    "        predictions = torch.argmin(distances, dim=1)\n",
    "        accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(path, has_labels=False):\n",
    "    \"\"\"Load and preprocess dataset\"\"\"\n",
    "    data = torch.load(path)\n",
    "    images = torch.tensor(data[\"data\"], dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "\n",
    "    # Normalize using ImageNet statistics\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])\n",
    "    images = (images / 255.0 - mean.view(1, 3, 1, 1)) / std.view(1, 3, 1, 1)\n",
    "\n",
    "    if has_labels:\n",
    "        labels = torch.tensor(data[\"targets\"], dtype=torch.long)\n",
    "        return DataLoader(list(zip(images, labels)), batch_size=64, shuffle=True)\n",
    "    return DataLoader(images, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# Training on D1\n",
    "def train_on_d1(base_path, eval_base_path):\n",
    "    \"\"\"\n",
    "    Function to train the model on dataset D1 and evaluate on D1.\n",
    "    This should be run first.\n",
    "    \"\"\"\n",
    "    # Initialize feature extractor and learner\n",
    "    feature_extractor = FeatureExtractor()\n",
    "    learner = ContinualLearner(feature_extractor)\n",
    "\n",
    "    # Load D1 training and evaluation data\n",
    "    print(\"Training on D1...\")\n",
    "    d1_train = load_dataset(f\"{base_path}/1_train_data.tar.pth\", has_labels=True)\n",
    "    d1_eval = load_dataset(f\"{eval_base_path}/1_eval_data.tar.pth\", has_labels=True)\n",
    "\n",
    "    # Train on D1\n",
    "    features, labels = learner.train_iteration(d1_train, dataset_id=1, initial=True)\n",
    "\n",
    "    # Save extracted features\n",
    "    learner.save_features(features, labels, dataset_id=1)\n",
    "\n",
    "    accuracy = learner.evaluate(d1_eval, dataset_id=1)\n",
    "    print(f\"Initial accuracy on D1: {accuracy:.4f}\")\n",
    "\n",
    "    return learner, accuracy\n",
    "\n",
    "\n",
    "# Training on Subsequent Datasets\n",
    "def train_subsequent_datasets(base_path, eval_base_path, learner, num_datasets=10):\n",
    "\n",
    "    # Initialize results matrix\n",
    "    accuracies = np.zeros((num_datasets, num_datasets))\n",
    "\n",
    "    # Record D1 accuracy\n",
    "    accuracies[0, 0] = learner.evaluate(load_dataset(f\"{eval_base_path}/1_eval_data.tar.pth\", has_labels=True))\n",
    "\n",
    "    # Train on subsequent datasets (D2 to Dn)\n",
    "    for i in range(2, num_datasets + 1):\n",
    "        print(f\"\\nProcessing dataset D{i}\")\n",
    "\n",
    "        train_data = load_dataset(f\"{base_path}/{i}_train_data.tar.pth\", has_labels=False)\n",
    "\n",
    "        # Train on current dataset\n",
    "        features, labels = learner.train_iteration(train_data, dataset_id=i, initial=False)\n",
    "\n",
    "        # Save extracted features\n",
    "        learner.save_features(features, labels, dataset_id=i)\n",
    "\n",
    "        # Evaluate on all datasets up to current\n",
    "        for j in range(1, i + 1):\n",
    "            eval_data = load_dataset(f\"{eval_base_path}/{j}_eval_data.tar.pth\", has_labels=True)\n",
    "            accuracy = learner.evaluate(eval_data, dataset_id=j)\n",
    "            accuracies[i - 1, j - 1] = accuracy\n",
    "            print(f\"Model {i} accuracy on D{j}: {accuracy:.4f}\")\n",
    "\n",
    "    learner.save_prototypes()\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "\n",
    "# Main Script\n",
    "if __name__ == \"__main__\":\n",
    "    base_path = \"dataset/part_one_dataset/train_data\"\n",
    "    eval_base_path = \"dataset/part_one_dataset/eval_data\"\n",
    "\n",
    "    print(\"Starting training on D1...\")\n",
    "    learner, initial_accuracy = train_on_d1(base_path, eval_base_path)\n",
    "\n",
    "    num_datasets = 10\n",
    "    print(\"Starting continual learning training on subsequent datasets...\")\n",
    "    accuracies = train_subsequent_datasets(base_path, eval_base_path, learner, num_datasets)\n",
    "\n",
    "    print(\"\\nFinal Accuracy Matrix:\")\n",
    "    print(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191d6f40-c3dc-4465-9a3d-69445fc5f831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
