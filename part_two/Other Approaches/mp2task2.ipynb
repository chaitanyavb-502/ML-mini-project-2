{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c7ef1a-7ccf-4df2-b539-01f1c332346b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prans\\anaconda3\\envs\\mlmini2\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\prans\\anaconda3\\envs\\mlmini2\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting continual learning training on subsequent datasets...\n",
      "\n",
      "Processing dataset D1\n",
      "Loading saved training features for dataset 1 from saved_data2\\features_dataset_1.pth\n",
      "Initial prototypes loaded from task 1\n",
      "Loading saved features for evaluation dataset 1 from saved_data2\\eval_features_dataset_1.pth\n",
      "Model 1 accuracy on D1: 0.6836\n",
      "\n",
      "Processing dataset D2\n",
      "Loading saved training features for dataset 2 from saved_data2\\features_dataset_2.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data2\\eval_features_dataset_1.pth\n",
      "Model 2 accuracy on D1: 0.6820\n",
      "Loading saved features for evaluation dataset 2 from saved_data2\\eval_features_dataset_2.pth\n",
      "Model 2 accuracy on D2: 0.5348\n",
      "\n",
      "Processing dataset D3\n",
      "Loading saved training features for dataset 3 from saved_data2\\features_dataset_3.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data2\\eval_features_dataset_1.pth\n",
      "Model 3 accuracy on D1: 0.6804\n",
      "Loading saved features for evaluation dataset 2 from saved_data2\\eval_features_dataset_2.pth\n",
      "Model 3 accuracy on D2: 0.5352\n",
      "Loading saved features for evaluation dataset 3 from saved_data2\\eval_features_dataset_3.pth\n",
      "Model 3 accuracy on D3: 0.7340\n",
      "\n",
      "Processing dataset D4\n",
      "Loading saved training features for dataset 4 from saved_data2\\features_dataset_4.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data2\\eval_features_dataset_1.pth\n",
      "Model 4 accuracy on D1: 0.6768\n",
      "Loading saved features for evaluation dataset 2 from saved_data2\\eval_features_dataset_2.pth\n",
      "Model 4 accuracy on D2: 0.5344\n",
      "Loading saved features for evaluation dataset 3 from saved_data2\\eval_features_dataset_3.pth\n",
      "Model 4 accuracy on D3: 0.7308\n",
      "Loading saved features for evaluation dataset 4 from saved_data2\\eval_features_dataset_4.pth\n",
      "Model 4 accuracy on D4: 0.7780\n",
      "\n",
      "Processing dataset D5\n",
      "Loading saved training features for dataset 5 from saved_data2\\features_dataset_5.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data2\\eval_features_dataset_1.pth\n",
      "Model 5 accuracy on D1: 0.6756\n",
      "Loading saved features for evaluation dataset 2 from saved_data2\\eval_features_dataset_2.pth\n",
      "Model 5 accuracy on D2: 0.5332\n",
      "Loading saved features for evaluation dataset 3 from saved_data2\\eval_features_dataset_3.pth\n",
      "Model 5 accuracy on D3: 0.7296\n",
      "Loading saved features for evaluation dataset 4 from saved_data2\\eval_features_dataset_4.pth\n",
      "Model 5 accuracy on D4: 0.7784\n",
      "Loading saved features for evaluation dataset 5 from saved_data2\\eval_features_dataset_5.pth\n",
      "Model 5 accuracy on D5: 0.8164\n",
      "\n",
      "Processing dataset D6\n",
      "Loading saved training features for dataset 6 from saved_data2\\features_dataset_6.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data2\\eval_features_dataset_1.pth\n",
      "Model 6 accuracy on D1: 0.6768\n",
      "Loading saved features for evaluation dataset 2 from saved_data2\\eval_features_dataset_2.pth\n",
      "Model 6 accuracy on D2: 0.5304\n",
      "Loading saved features for evaluation dataset 3 from saved_data2\\eval_features_dataset_3.pth\n",
      "Model 6 accuracy on D3: 0.7308\n",
      "Loading saved features for evaluation dataset 4 from saved_data2\\eval_features_dataset_4.pth\n",
      "Model 6 accuracy on D4: 0.7776\n",
      "Loading saved features for evaluation dataset 5 from saved_data2\\eval_features_dataset_5.pth\n",
      "Model 6 accuracy on D5: 0.8176\n",
      "Loading saved features for evaluation dataset 6 from saved_data2\\eval_features_dataset_6.pth\n",
      "Model 6 accuracy on D6: 0.6932\n",
      "\n",
      "Processing dataset D7\n",
      "Loading saved training features for dataset 7 from saved_data2\\features_dataset_7.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data2\\eval_features_dataset_1.pth\n",
      "Model 7 accuracy on D1: 0.6768\n",
      "Loading saved features for evaluation dataset 2 from saved_data2\\eval_features_dataset_2.pth\n",
      "Model 7 accuracy on D2: 0.5284\n",
      "Loading saved features for evaluation dataset 3 from saved_data2\\eval_features_dataset_3.pth\n",
      "Model 7 accuracy on D3: 0.7308\n",
      "Loading saved features for evaluation dataset 4 from saved_data2\\eval_features_dataset_4.pth\n",
      "Model 7 accuracy on D4: 0.7768\n",
      "Loading saved features for evaluation dataset 5 from saved_data2\\eval_features_dataset_5.pth\n",
      "Model 7 accuracy on D5: 0.8144\n",
      "Loading saved features for evaluation dataset 6 from saved_data2\\eval_features_dataset_6.pth\n",
      "Model 7 accuracy on D6: 0.6916\n",
      "Loading saved features for evaluation dataset 7 from saved_data2\\eval_features_dataset_7.pth\n",
      "Model 7 accuracy on D7: 0.7036\n",
      "\n",
      "Processing dataset D8\n",
      "Loading saved training features for dataset 8 from saved_data2\\features_dataset_8.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data2\\eval_features_dataset_1.pth\n",
      "Model 8 accuracy on D1: 0.6744\n",
      "Loading saved features for evaluation dataset 2 from saved_data2\\eval_features_dataset_2.pth\n",
      "Model 8 accuracy on D2: 0.5276\n",
      "Loading saved features for evaluation dataset 3 from saved_data2\\eval_features_dataset_3.pth\n",
      "Model 8 accuracy on D3: 0.7304\n",
      "Loading saved features for evaluation dataset 4 from saved_data2\\eval_features_dataset_4.pth\n",
      "Model 8 accuracy on D4: 0.7740\n",
      "Loading saved features for evaluation dataset 5 from saved_data2\\eval_features_dataset_5.pth\n",
      "Model 8 accuracy on D5: 0.8128\n",
      "Loading saved features for evaluation dataset 6 from saved_data2\\eval_features_dataset_6.pth\n",
      "Model 8 accuracy on D6: 0.6900\n",
      "Loading saved features for evaluation dataset 7 from saved_data2\\eval_features_dataset_7.pth\n",
      "Model 8 accuracy on D7: 0.7012\n",
      "Loading saved features for evaluation dataset 8 from saved_data2\\eval_features_dataset_8.pth\n",
      "Model 8 accuracy on D8: 0.7084\n",
      "\n",
      "Processing dataset D9\n",
      "Loading saved training features for dataset 9 from saved_data2\\features_dataset_9.pth\n",
      "Loading saved features for evaluation dataset 1 from saved_data2\\eval_features_dataset_1.pth\n",
      "Model 9 accuracy on D1: 0.6704\n",
      "Loading saved features for evaluation dataset 2 from saved_data2\\eval_features_dataset_2.pth\n",
      "Model 9 accuracy on D2: 0.5212\n",
      "Loading saved features for evaluation dataset 3 from saved_data2\\eval_features_dataset_3.pth\n",
      "Model 9 accuracy on D3: 0.7256\n",
      "Loading saved features for evaluation dataset 4 from saved_data2\\eval_features_dataset_4.pth\n",
      "Model 9 accuracy on D4: 0.7688\n",
      "Loading saved features for evaluation dataset 5 from saved_data2\\eval_features_dataset_5.pth\n",
      "Model 9 accuracy on D5: 0.8080\n",
      "Loading saved features for evaluation dataset 6 from saved_data2\\eval_features_dataset_6.pth\n",
      "Model 9 accuracy on D6: 0.6888\n",
      "Loading saved features for evaluation dataset 7 from saved_data2\\eval_features_dataset_7.pth\n",
      "Model 9 accuracy on D7: 0.6960\n",
      "Loading saved features for evaluation dataset 8 from saved_data2\\eval_features_dataset_8.pth\n",
      "Model 9 accuracy on D8: 0.7076\n",
      "Loading saved features for evaluation dataset 9 from saved_data2\\eval_features_dataset_9.pth\n",
      "Model 9 accuracy on D9: 0.6108\n",
      "\n",
      "Processing dataset D10\n",
      "Saved features for training dataset 10 not found. Extracting features...\n",
      "Loading saved features for evaluation dataset 1 from saved_data2\\eval_features_dataset_1.pth\n",
      "Model 10 accuracy on D1: 0.6676\n",
      "Loading saved features for evaluation dataset 2 from saved_data2\\eval_features_dataset_2.pth\n",
      "Model 10 accuracy on D2: 0.5228\n",
      "Loading saved features for evaluation dataset 3 from saved_data2\\eval_features_dataset_3.pth\n",
      "Model 10 accuracy on D3: 0.7244\n",
      "Loading saved features for evaluation dataset 4 from saved_data2\\eval_features_dataset_4.pth\n",
      "Model 10 accuracy on D4: 0.7676\n",
      "Loading saved features for evaluation dataset 5 from saved_data2\\eval_features_dataset_5.pth\n",
      "Model 10 accuracy on D5: 0.8080\n",
      "Loading saved features for evaluation dataset 6 from saved_data2\\eval_features_dataset_6.pth\n",
      "Model 10 accuracy on D6: 0.6872\n",
      "Loading saved features for evaluation dataset 7 from saved_data2\\eval_features_dataset_7.pth\n",
      "Model 10 accuracy on D7: 0.6956\n",
      "Loading saved features for evaluation dataset 8 from saved_data2\\eval_features_dataset_8.pth\n",
      "Model 10 accuracy on D8: 0.7076\n",
      "Loading saved features for evaluation dataset 9 from saved_data2\\eval_features_dataset_9.pth\n",
      "Model 10 accuracy on D9: 0.6128\n",
      "Saved features for dataset 10 not found. Extracting features...\n",
      "Model 10 accuracy on D10: 0.7912\n",
      "\n",
      "Final Accuracy Matrix:\n",
      "[[0.6836 0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.682  0.5348 0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.6804 0.5352 0.734  0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.6768 0.5344 0.7308 0.778  0.     0.     0.     0.     0.     0.    ]\n",
      " [0.6756 0.5332 0.7296 0.7784 0.8164 0.     0.     0.     0.     0.    ]\n",
      " [0.6768 0.5304 0.7308 0.7776 0.8176 0.6932 0.     0.     0.     0.    ]\n",
      " [0.6768 0.5284 0.7308 0.7768 0.8144 0.6916 0.7036 0.     0.     0.    ]\n",
      " [0.6744 0.5276 0.7304 0.774  0.8128 0.69   0.7012 0.7084 0.     0.    ]\n",
      " [0.6704 0.5212 0.7256 0.7688 0.808  0.6888 0.696  0.7076 0.6108 0.    ]\n",
      " [0.6676 0.5228 0.7244 0.7676 0.808  0.6872 0.6956 0.7076 0.6128 0.7912]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define FeatureExtractor\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.efficientnet = models.efficientnet_b0(pretrained=True)\n",
    "        self.efficientnet.eval()\n",
    "        self.efficientnet.classifier = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = Resize((160, 160))(x)\n",
    "        x = self.efficientnet(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Function to compute prototypes\n",
    "def compute_prototypes(features, labels, n_classes):\n",
    "    \"\"\"Compute prototypes for each class\"\"\"\n",
    "    prototypes = []\n",
    "    for class_idx in range(n_classes):\n",
    "        class_features = features[labels == class_idx]\n",
    "        if len(class_features) > 0:\n",
    "            class_prototype = class_features.mean(0)\n",
    "            prototypes.append(class_prototype)\n",
    "    return torch.stack(prototypes)\n",
    "\n",
    "\n",
    "# Continual Learner Class\n",
    "class ContinualLearner:\n",
    "    def __init__(self, feature_extractor, n_classes=10, output_dir=\"saved_data2\"):\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.n_classes = n_classes\n",
    "        self.prototypes = None\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def extract_features(self, dataloader):\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                if isinstance(batch, (tuple, list)):\n",
    "                    images, labels = batch\n",
    "                    all_labels.append(labels)\n",
    "                else:\n",
    "                    images = batch\n",
    "                features = self.feature_extractor(images)\n",
    "                all_features.append(features)\n",
    "\n",
    "        features = torch.cat(all_features)\n",
    "        labels = torch.cat(all_labels) if all_labels else None\n",
    "        return features, labels\n",
    "\n",
    "    def save_features(self, features, labels, dataset_id):\n",
    "        \"\"\"Save extracted features and labels to a file.\"\"\"\n",
    "        torch.save(\n",
    "            {\"features\": features.cpu(), \"labels\": labels.cpu() if labels is not None else None},\n",
    "            os.path.join(self.output_dir, f\"features_dataset_{dataset_id}.pth\"),\n",
    "        )\n",
    "\n",
    "    def save_prototypes(self):\n",
    "        \"\"\"Save the current prototypes to a file.\"\"\"\n",
    "        torch.save(self.prototypes.cpu(), os.path.join(self.output_dir, \"final_prototypes.pth\"))\n",
    "\n",
    "    def assign_pseudo_labels(self, features):\n",
    "        \"\"\"Assign pseudo-labels using current prototypes\"\"\"\n",
    "        distances = torch.cdist(features, self.prototypes)\n",
    "        pseudo_labels = torch.argmin(distances, dim=1)\n",
    "        confidence_scores = torch.softmax(-distances, dim=1).max(dim=1)[0]\n",
    "        return pseudo_labels, confidence_scores\n",
    "\n",
    "    def update_prototypes(self, features, pseudo_labels, confidence_scores, threshold=0):\n",
    "        \"\"\"Update prototypes using high-confidence samples\"\"\"\n",
    "        new_prototypes = []\n",
    "        for class_idx in range(self.n_classes):\n",
    "            mask = (pseudo_labels == class_idx) & (confidence_scores > threshold)\n",
    "            if mask.sum() > 0:\n",
    "                class_features = features[mask]\n",
    "                new_prototype = class_features.mean(0)\n",
    "                new_prototypes.append(new_prototype)\n",
    "            else:\n",
    "                new_prototypes.append(self.prototypes[class_idx])\n",
    "        return torch.stack(new_prototypes)\n",
    "\n",
    "    def load_initial_prototypes(self, path=\"saved_data/final_prototypes.pth\"):\n",
    "        \"\"\"Load initial prototypes from task 1\"\"\"\n",
    "        self.prototypes = torch.load(path)\n",
    "        print(\"Initial prototypes loaded from task 1\")\n",
    "\n",
    "    def train_iteration(self, train_loader, dataset_id=None, initial=False):\n",
    "        \"\"\"Train on a new dataset, using saved features if available.\"\"\"\n",
    "        if dataset_id is not None:\n",
    "            # Check if saved training features exist\n",
    "            saved_path = os.path.join(self.output_dir, f\"features_dataset_{dataset_id}.pth\")\n",
    "            if os.path.exists(saved_path):\n",
    "                print(f\"Loading saved training features for dataset {dataset_id} from {saved_path}\")\n",
    "                saved_data = torch.load(saved_path)\n",
    "                features = saved_data[\"features\"]\n",
    "                labels = saved_data[\"labels\"]\n",
    "            else:\n",
    "                print(f\"Saved features for training dataset {dataset_id} not found. Extracting features...\")\n",
    "                features, labels = self.extract_features(train_loader)\n",
    "                self.save_features(features, labels, dataset_id)  # Save extracted features for future use\n",
    "        else:\n",
    "            print(\"Dataset ID not provided, extracting features directly...\")\n",
    "            features, labels = self.extract_features(train_loader)\n",
    "\n",
    "        if initial:\n",
    "            # For the first dataset in task 2, use initial prototypes from task 1\n",
    "            self.load_initial_prototypes()\n",
    "        else:\n",
    "            # For subsequent datasets, use pseudo-labels\n",
    "            pseudo_labels, confidence_scores = self.assign_pseudo_labels(features)\n",
    "            self.prototypes = 0.9 * self.prototypes + 0.1 * self.update_prototypes(\n",
    "                features, pseudo_labels, confidence_scores\n",
    "            )\n",
    "\n",
    "        return features, labels\n",
    "\n",
    "    def save_eval_features(self, features, labels, dataset_id):\n",
    "        \"\"\"Save extracted evaluation features and labels to a file.\"\"\"\n",
    "        torch.save(\n",
    "        {\"features\": features.cpu(), \"labels\": labels.cpu()},\n",
    "        os.path.join(self.output_dir, f\"eval_features_dataset_{dataset_id}.pth\"),\n",
    "        )\n",
    "\n",
    "    def evaluate(self, eval_loader, dataset_id=None):\n",
    "        \"\"\"Evaluate on a labeled dataset, using saved features if available.\"\"\"\n",
    "        if dataset_id is not None:\n",
    "            # Check if saved features exist\n",
    "            saved_path = os.path.join(self.output_dir, f\"eval_features_dataset_{dataset_id}.pth\")\n",
    "            if os.path.exists(saved_path):\n",
    "                print(f\"Loading saved features for evaluation dataset {dataset_id} from {saved_path}\")\n",
    "                saved_data = torch.load(saved_path)\n",
    "                features = saved_data[\"features\"]\n",
    "                labels = saved_data[\"labels\"]\n",
    "            else:\n",
    "                print(f\"Saved features for dataset {dataset_id} not found. Extracting features...\")\n",
    "                features, labels = self.extract_features(eval_loader)\n",
    "                self.save_eval_features(features, labels, dataset_id)  # Save extracted features for future use\n",
    "        else:\n",
    "            print(\"Dataset ID not provided, extracting features directly...\")\n",
    "            features, labels = self.extract_features(eval_loader)\n",
    "\n",
    "        # Perform evaluation using extracted or loaded features\n",
    "        distances = torch.cdist(features, self.prototypes)\n",
    "        predictions = torch.argmin(distances, dim=1)\n",
    "        accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "# Function to load dataset\n",
    "def load_dataset(path, has_labels=False):\n",
    "    \"\"\"Load and preprocess dataset\"\"\"\n",
    "    data = torch.load(path)\n",
    "    images = torch.tensor(data[\"data\"], dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "\n",
    "    # Normalize using ImageNet statistics\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])\n",
    "    images = (images / 255.0 - mean.view(1, 3, 1, 1)) / std.view(1, 3, 1, 1)\n",
    "\n",
    "    if has_labels:\n",
    "        labels = torch.tensor(data[\"targets\"], dtype=torch.long)\n",
    "        return DataLoader(list(zip(images, labels)), batch_size=64, shuffle=True)\n",
    "    return DataLoader(images, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# Training on Subsequent Datasets\n",
    "def train_subsequent_datasets(base_path, eval_base_path, learner, num_datasets=10):\n",
    "    \"\"\"\n",
    "    Function to train the model on subsequent datasets and evaluate on previous datasets.\n",
    "    This function should be run after training on the final dataset of task 1.\n",
    "    \"\"\"\n",
    "    # Initialize results matrix\n",
    "    accuracies = np.zeros((num_datasets, 10))  # 20 columns to accommodate both task 1 and task 2 datasets\n",
    "\n",
    "    # Train on subsequent datasets (D11 to D20)\n",
    "    for i in range(1, 11):\n",
    "        print(f\"\\nProcessing dataset D{i}\")\n",
    "\n",
    "        # Load current training dataset (first iteration uses initial prototypes from task 1)\n",
    "        train_data = load_dataset(f\"{base_path}/{i}_train_data.tar.pth\", has_labels=False)\n",
    "\n",
    "        # Train on current dataset (initial is True only for the first dataset)\n",
    "        features, labels = learner.train_iteration(train_data, dataset_id=i, initial=(i==1))\n",
    "\n",
    "        # Save extracted features\n",
    "        learner.save_features(features, labels, dataset_id=i)\n",
    "\n",
    "        # Evaluate on all previous datasets (including task 1 datasets)\n",
    "        for j in range(1, i + 1):\n",
    "            eval_data = load_dataset(f\"{eval_base_path}/{j}_eval_data.tar.pth\", has_labels=True)\n",
    "            accuracy = learner.evaluate(eval_data, dataset_id=j)\n",
    "            accuracies[i - 1, j - 1] = accuracy\n",
    "            print(f\"Model {i} accuracy on D{j}: {accuracy:.4f}\")\n",
    "\n",
    "    # Save final prototypes after training on all datasets\n",
    "    learner.save_prototypes()\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "\n",
    "# Main Script\n",
    "if __name__ == \"__main__\":\n",
    "    base_path = \"dataset/part_two_dataset/train_data\"\n",
    "    eval_base_path = \"dataset/part_two_dataset/eval_data\"\n",
    "\n",
    "    # Initialize feature extractor and learner\n",
    "    feature_extractor = FeatureExtractor()\n",
    "    learner = ContinualLearner(feature_extractor, output_dir=\"saved_data2\")\n",
    "\n",
    "    num_datasets = 10\n",
    "    print(\"Starting continual learning training on subsequent datasets...\")\n",
    "    accuracies = train_subsequent_datasets(base_path, eval_base_path, learner, num_datasets)\n",
    "\n",
    "    print(\"\\nFinal Accuracy Matrix:\")\n",
    "    print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e99cfd-6285-4334-9f4b-374abe6ba700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
